---
title: "Figures for paper"
author: "Rachael 'Rocky' Aikens, Voight Lab"
date: "August 3, 2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = '../../data')

library(ggplot2)
library(gplots)
library(stats)
library(readr)
library(dplyr)
library(knitr)
require(reshape2)
library(gridExtra)
library(grid)
require("ggrepel")
```

# Table 1

To make this table, we need the following **functions** and *datasets*:

* *3mer count dataframes for all ancestral continental groups, in 1,000 genomes and SGDP*

```{r F1BCD setup data}
AFR_3mer_counts <- read_delim("3mer/AFR_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
EUR_3mer_counts <- read_delim("3mer/EUR_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
EAS_3mer_counts <- read_delim("3mer/EAS_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
SAS_3mer_counts <- read_delim("3mer/SAS_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)

SGDP_AFR_3mer_counts <- read_delim("3mer/SGDP_AFR_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
SGDP_EUR_3mer_counts <- read_delim("3mer/SGDP_EUR_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
SGDP_EAS_3mer_counts <- read_delim("3mer/SGDP_EAS_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
SGDP_SAS_3mer_counts <- read_delim("3mer/SGDP_SAS_3mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
```

* **Fourway.chi** Tests for heterogeneity among any four count dataframes
* **ordered.p** performs ordered p value correction

```{r T1 setup methods}
# calculates homogeneity test p values for Fourway comparisons of counts dfs
fourway.chi <- function(AFR, EUR, EAS, SAS, filter = T){
  n.contexts = length(AFR$Context)
  
  # make dataframe for results
  result <- data.frame(matrix(ncol=9,nrow=n.contexts))
  colnames(result) <- c("Context", "X5mer","X3mer", "X1mer", 
                        "AFR.Count", "EUR.Count", "EAS.Count", "SAS.Count", "p")
  result$Context <- AFR$Context
  result$X5mer <- AFR$X5mer # for smaller contexts, X3mer and X5mer columns do not exist,
  result$X3mer <- AFR$X3mer # and will disappear at this step
  result$X1mer <- AFR$X1mer 
  result$AFR.Count <- AFR$Count; result$EUR.Count <- EUR$Count
  result$EAS.Count <- EAS$Count; result$SAS.Count <- SAS$Count
  
  # start setting up tables
  sums <- c(sum(AFR$Count), sum(EUR$Count), sum(EAS$Count), sum(SAS$Count))
  
  # set up table and run test for each context
  for (i in 1:n.contexts){
    c.a <- c(AFR$Count[i], EUR$Count[i], EAS$Count[i], SAS$Count[i])
    c.b <- sums - c.a
    data <- cbind(c.a, c.b)
    warning <- is(tryCatch(chisq.test(data), warning = function(w) w), "warning")
    if (filter == T & warning){
      result$p[i] <- NA}
    else result$p[i] <- chisq.test(data)$p.value
    }
  return(result)
}

ordered.p <- function(pdata){
  # order data by p value (consider NAs largest)
  myorder <- order(pdata$p)
  n.muts <- length(pdata$p)
  
  p.ordered <- rep(0, n.muts)
  
  # set largest p-value 
  j <- myorder[n.muts]
  p.ordered[j] <- pdata$p[j]
  
  # initialize not mutated counts based on this lowest p-value mutation
  not.mut <- c(pdata$AFR.Count[j], pdata$EUR.Count[j], 
               pdata$EAS.Count[j], pdata$SAS.Count[j])
  
  for (i in n.muts:1){
    j <- myorder[i]
    mut <-c(pdata$AFR.Count[j], pdata$EUR.Count[j], 
            pdata$EAS.Count[j], pdata$SAS.Count[j])
    data <- cbind(mut, not.mut)
    w.e <- tryCatch(chisq.test(data), warning = function(w) w, error = function(e) e)
    warning <- is(w.e, "warning")
    error <- is(w.e, "error")
    if (warning | error){
      p.ordered[j] <- NA} else {p.ordered[j] <- chisq.test(data)$p.value}
        
    # add these mutations to the not.mutated counts for future tests
    not.mut <- not.mut + mut
  }
  pdata$p <- p.ordered
  return(pdata)
}

pairwise.op <- function(pdata){
  # preprocess data to order and remove nas 
  pdata <- pdata[complete.cases(pdata$p),]
  myorder <- order(pdata$p)
  n.muts <- length(pdata$p)
  
  p.ordered <- rep(0, n.muts)
  
  # set largest p-value 
  j <- myorder[n.muts]
  p.ordered[j] <- pdata$p[j]
  
  # initialize not mutated counts based on this lowest p-value mutation
  not.mut <- c(pdata$Counts1[j], pdata$Counts2[j])
  
  for (i in n.muts:1){
    j <- myorder[i]
    mut <-c(pdata$Counts1[j], pdata$Counts2[j])
    data <- cbind(mut, not.mut)
    p.ordered[j] <- chisq.test(data)$p.value
    
    # add these mutations to the not.mutated counts for future tests
    not.mut <- not.mut + mut
  }
  pdata$p <- p.ordered
  return(pdata)
}
```

* **Pairwise.chi** Tests for heterogeneity between any two count dataframes
```{r pairwise.chi, echo = F}
# calculates homogeneity test p values for pairwise comparisons of two dfs of counts
pairwise.chi <- function(counts.1, counts.2, filter = T){
  n.contexts = length(counts.1$Context)
  result <- data.frame(matrix(ncol=4,nrow=n.contexts))
  colnames(result) <- c("Context", "Counts1", "Counts2", "p")
  
  result$Context <- counts.1$Context
  sum.1 <- sum(counts.1$Count)
  sum.2 <- sum(counts.2$Count)

  for (i in 1:n.contexts){
    c.a <- c(counts.1$Count[i], counts.2$Count[i])
    c.b <- c(sum.1, sum.2) - c.a
    data <- cbind(c.a, c.b)
    
    result$Counts1[i] <- c.a[1]
    result$Counts2[i] <- c.a[2]
    warning <- is(tryCatch(chisq.test(data), warning = function(w) w), "warning")
    if (filter == T & warning){
      result$p[i] <- NA
    }
    else result$p[i] <- chisq.test(data)$p.value
  }
  
  return(result)
}
```


```{r Table1 make1}
# calculate ordered p valuesn in KG and SGDP
o.p.3mer <- fourway.chi(AFR_3mer_counts, EUR_3mer_counts, EAS_3mer_counts, SAS_3mer_counts) %>%
  ordered.p()

# create rate table and order by p value
rates <- cbind(AFR_3mer_counts$Rate, EUR_3mer_counts$Rate, SAS_3mer_counts$Rate, EAS_3mer_counts$Rate)
rate_table <- cbind(o.p.3mer$Context, round(rates/AFR_3mer_counts$Rate, digits = 2), o.p.3mer$p)
rate_table <- rate_table[order(o.p.3mer$p),]


# load reference dataframe of SGDP replication
SGDP_KG_Agreement <-read_delim("SGDP_KG_Agreement_table.txt", ",", escape_double = FALSE, trim_ws = TRUE)

# join withg reference and show top 15 replicated results
table1 <- left_join(data.frame(rate_table), SGDP_KG_Agreement, by = c("X1" = "Context")) %>% 
  filter(Agreement %in% c("Agree", "Agree Mostly", "Agree Somewhat")) %>%
  head(n = 14) %>% dplyr::select(-c(X6, Agreement, Notes))

colnames(table1)<- c("Context", "AFR relative rate", "EUR relative rate", "SAS relative rate", "EAS relative rate", "p (1,000 genomes)", "p (SGDP)")

# plot significant 7mers and print most signif. new results
kable(table1, digits = 600, row.names = F,
      caption = "14 most significant 3mers using ordered p value correction")
```

Certain table entries are bold if they are significantly enriched in Africa.  The code below calculates which threemers are significantly different (p<1e-5) between AFR and EUR in table 1.

```{r find pairwise}
pAFRvEUR <- pairwise.chi(AFR_3mer_counts, EUR_3mer_counts)
opAFRvEUR <- pairwise.op(pAFRvEUR)
opAFRvEUR <- subset(opAFRvEUR, opAFRvEUR$p < 1e-5)
kable(subset(opAFRvEUR, is.element(opAFRvEUR$Context, table1[,1])))
```
Here are the remaining comparisons:

```{r}
# South Asia
pAFRvSAS <- pairwise.chi(AFR_3mer_counts, SAS_3mer_counts)
opAFRvSAS <- pairwise.op(pAFRvSAS)
opAFRvSAS <- subset(opAFRvSAS, opAFRvSAS$p < 1e-5)
kable(subset(opAFRvSAS, is.element(opAFRvSAS$Context, table1[,1])))

# East Asia
pAFRvEAS <- pairwise.chi(AFR_3mer_counts, EAS_3mer_counts)
opAFRvEAS <- pairwise.op(pAFRvEAS)
opAFRvEAS <- subset(opAFRvEAS, opAFRvEAS$p < 1e-5)
kable(subset(opAFRvEAS, is.element(opAFRvEAS$Context, table1[,1])))
```


# Figure 1

## A: heatmap of all 3mer mutation types

To make this figure, we need the following **functions** and *datasets*:

* **norm/norm.byrow** need these to normalize the data before making a heatmap
* **make.heatmap** calls heatmap2 to make a heatmap.  The function defined herein is slightly different from the one in the heatmaps_report workflow; there are some small modifications to format the dendrogram and plot area specifically for this figure.
* *3mer rate matrix* saved in 'rate_profiles/rates_3mer.txt'

```{r F1A setup data}
# data 
rates.3mer <- as.matrix(read.delim("rate_profiles/rates_3mer.txt"))

subpops.names <- c("TSI", "IBS", "CEU", "GBR", "FIN", "STU", "ITU", "BEB", "GIH", "PJL",
                   "ESN", "GWD", "LWK", "MSL", "YRI", "CDX", "CHB", "CHS", "JPT", "KHV")
```

```{r F1A setup methods}
# helper function that normalizes a vector by z or L1 method
norm <- function(vec, method = c("z", "L1", "fdiff")){
  if (method == "L1"){ # normalize so vector sums to 1
    u <- vec/sum(abs(vec))}
  else if (method == "z"){ # normalize to mean 0, variance 1
    u <- (vec - mean(vec))/sd(vec)}
  else # normalize to fold change compared to mean
    u <- vec/mean(vec)
  return(u)
}

# normalizes a whole dataset by calling norm on each row
norm.byrow <- function(mat, m){
  data <- t(apply(mat,1,norm, method = m))
  return(data)
}

# makes a heatmap of a matrix and returns the row dendrogram as an object
# this function is rewritten for making figure 1 of my paper. Won't work for most other applications.
make.heatmap <- function(data, logunits = T){
  
  complete <- apply(data, 1, function(row) all(row != 0) & all(!is.na(row)))
  data <- data[complete,]
  
  if (logunits == T) {
    data <- log2(data)
  }
  
  dr <- hclust(dist(data))
  dc <- hclust(dist(t(data)))
  
  weights.dr <- ifelse(rownames(data) == "TCT->T", yes = 11, no = 0) + ifelse(rownames(data) == "TCC->T", yes = 11, no = 0)+
                ifelse(rownames(data) == "GAT->T", yes = 8, no = 0) + ifelse(rownames(data) == "ACG->T", yes = 9, no = 0) +     
                ifelse(rownames(data) == "AAC->C", yes = 7, no = 0) + ifelse(rownames(data) == "TAT->T", yes = 6, no = 0)
    
  
  dr.ordered <- reorder(as.dendrogram(dr), wts = weights.dr, agglo.FUN = mean)
  
  heatmap.2(data, Rowv = dr.ordered, Colv = as.dendrogram(dc),
            trace = 'none', col=colorRampPalette(c('blue', "white", 'red'))(n = 1000), labRow = T, #to remove row names, add, "labRow = T"
            density.info = 'none', key.xlab = "fold differece vs. mean\n(log base 2 scale)",
            key.title = NA, keysize = 0.5, key.par = list(cex=0.65),
            lhei = c(1,5.5), lwid = c(1,4))
  return(dr)
}
```

```{r F1A preprocess data}
norm.3mer.rates <- norm.byrow(rates.3mer, "fdiff")
```

```{r F1A make, fig.height=6.25, fig.width=5.86}
dr <- make.heatmap(norm.3mer.rates)
```

## BCE: CI plots of polymorphism clusters

To make these panels, I need the following **functions** and *datasets*:

* **CI.plot.bygroup** Makes a plot of the rates of a group of mutations.  Will bug out if the mutations are of the same context, although that's not a problem for these figures.


```{r F1BCD setup methods}
CI.plot.bygroup <- function(AFR, EUR, EAS, SAS, muts, groupname = "mutation group") {
  #NOTE: muts must all be from different contexts.  Otherwise this will do weird things.
  
  muts.i <- which(is.element(AFR$Context, muts))
  popnames <- c("Africa","Europe", "South\nAsia\n\n", "East\nAsia\n\n")
  colors <- c("forestgreen", "darkblue", "magenta","red")
  
  #have to do a silly workaround or R will sort popnames alphanumerically
  poplabs <- factor(popnames, levels= popnames)
  
  #cycle through pops and get counts for mut
  counts <- rep(0, 4)
  sums <- rep(0, 4)
  pops <- list(AFR, EUR, SAS, EAS)
  
  for (i in 1:length(pops)){
    counts[i] <- sum(pops[[i]]$Count[muts.i]) #number of obersvations of muts in pop
    sums[i]<- sum(pops[[i]]$Count)#total polymorphisms in pop
  }
  
  #estimate substitution probability
  N.c <- sum(AFR$context_in_genome[muts.i])
  theta <- counts/N.c
  L <- theta - 1.96*sqrt(theta*(1-theta)/N.c)
  U <- theta + 1.96*sqrt(theta*(1-theta)/N.c)
  
  #normalize to rate estimate; assume genome wide subsitution probability is measured without error
  norm <- 1.2E-8*(sum(as.numeric(AFR$context_in_genome))/3)/sums
  
  df <- data.frame(cbind(popnames, theta*norm, L*norm, U*norm))
  plotcol <- reorder(colors, theta*norm)
  
  CI.plot <- ggplot(df, aes(reorder(popnames, c(1,2,3,4)), theta*norm)) +
    geom_point(size = 3, color = plotcol) +
    geom_errorbar(aes(ymax = U*norm, ymin = L*norm), color = plotcol, size =.75)+
    labs(title = paste("Estimated mutation\nrate of", groupname), y = NULL) + #y axis label
    theme(axis.text.x = element_text(size = rel(.8)), axis.title.x = element_blank(), #adjust text sizes
          axis.title.y = element_text(size = rel(.9)), axis.text.y = element_text(size = rel(.9), angle = 0, hjust = 0.5), title = element_text(size = rel(.7)),
          legend.position = 'none')
  return(CI.plot)
}

```

```{r F1BCD make, fig.height=2.5, fig.width=6.5}
s1 <- c("TCT->T", "ACC->T", "TCA->T", "CCC->T", "ACT->T", "TCC->T", "GCC->T")
a <- CI.plot.bygroup(AFR_3mer_counts, EUR_3mer_counts, EAS_3mer_counts, SAS_3mer_counts, s1, "profile #1")

s2 <- c("GAT->T", "ACC->A", "GAC->T")
b <- CI.plot.bygroup(AFR_3mer_counts, EUR_3mer_counts, EAS_3mer_counts, SAS_3mer_counts, s2, "profile #2")

s4 <-c("ACG->T", "CCG->T", "GCG->T", "TCG->T")
d <- CI.plot.bygroup(AFR_3mer_counts, EUR_3mer_counts, EAS_3mer_counts, SAS_3mer_counts, s4, "profile #4")
```

## D: CI plots for signal 3

This figure was harder to make, and we'll probably revamp the way we do it.  Once we've figured that out, I'll add that code here.  For now, this figure requires the following:

* **CI.plotsubpop.bygroup** same as CI.plot.bygroup, but works for more populations than just the ancestral continental groups.
* *3mer count dataframes for all ancestral continental groups (except EAS)*
* *3mer count dataframes for all EAS subpopulations*

```{r F1E setup data}
# EAST ASIA
CHB_EAS_3mer_counts <- read_delim("subpops/3mer/CHB_EAS_3mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
JPT_EAS_3mer_counts <- read_delim("subpops/3mer/JPT_EAS_3mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
CHS_EAS_3mer_counts <- read_delim("subpops/3mer/CHS_EAS_3mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
CDX_EAS_3mer_counts <- read_delim("subpops/3mer/CDX_EAS_3mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
KHV_EAS_3mer_counts <- read_delim("subpops/3mer/KHV_EAS_3mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
```

```{r F1E setup methods}
CI.plot.subpop.bygroup <- function(subpops, muts, popnames, colors = colors.ancestral, groupname = "mutation group"){
  n.pops <- length(subpops)
  mut.i <- which(is.element(subpops[[1]]$Context, muts))
  
  #have to do a silly workaround or R will sort popnames alphanumerically
  poplabs <- factor(popnames, levels= popnames)
  
  #cycle through subpops and get counts for mut
  counts <- rep(0, n.pops)
  sums <- rep(0, n.pops)
  for (i in 1:n.pops){
    counts[i] <- sum(subpops[[i]]$Count[mut.i])
    sums[i]<- sum(subpops[[i]]$Count)
  }
  
  #estimate substitution probability
  N.c <- sum(subpops[[1]]$context_in_genome[mut.i]) 
  theta <- counts/N.c
  L <- theta - 1.96*sqrt(theta*(1-theta)/N.c)
  U <- theta + 1.96*sqrt(theta*(1-theta)/N.c)
  
  #normalize to rate estimate; assume genome wide subsitution probability is measured without error
  norm <- 1.2E-8*(sum(as.numeric(subpops[[1]]$context_in_genome))/3)/sums
  
  
  df <- data.frame(cbind(poplabs, theta*norm, L*norm, U*norm))
  plotcol <- reorder(colors, theta*norm)
  
  ggplot(df, aes(reorder(popnames, poplabs), theta*norm)) +
    geom_point(size = 3, color = plotcol) +
    geom_errorbar(aes(ymax = U*norm, ymin = L*norm), color = plotcol, size = .75)+
    labs(title = paste("Estimated mutation\nrate of", groupname), y = NULL) + #y axis label
    theme(axis.text.x = element_text(size = rel(.8), angle = 45, hjust = 1), axis.title.x = element_blank(), #adjust text sizes
          axis.title.y = element_text(size = rel(.8)), axis.text.y = element_text(size = rel(.9)),
          title = element_text(size = rel(.7)),
          legend.position = 'none')
}
```

```{r F1E format data}
subpops1E <- list(AFR_3mer_counts, EUR_3mer_counts, SAS_3mer_counts, CDX_EAS_3mer_counts, KHV_EAS_3mer_counts, CHS_EAS_3mer_counts, CHB_EAS_3mer_counts, JPT_EAS_3mer_counts)
colors1E <- c("forestgreen", "darkblue", "magenta", rep("red", 5))
popnames1E <- c("Africa", "Europe", "South Asia", "CDX", "KHV", "CHS", "CHB", "JPT")
muts1E <- c("CAC->C", "TAT->T", "GAC->C", "AAC->C", "TAC->C")
```

```{r F1E make, fig.height=3, fig.width = 9}
c <- CI.plot.subpop.bygroup(subpops1E, muts1E, popnames1E, colors1E, "profile #3")
grid.draw(cbind(ggplotGrob(a), ggplotGrob(b), ggplotGrob(c), ggplotGrob(d), size = "last"))
```

# Figure 2

## AB: scatter plot examples

To make these figures, I need

* **subrate.scplot** makes a scatterplot of all 7mers with a given 3mer subtype.
* *7mer count dataframes for JPT and CDX*
* *7mer count dataframes for East Asia and Europe*

```{r F2AB setup data}
EUR_7mer_counts <- read_delim("7mer/EUR_7mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
EAS_7mer_counts <- read_delim("7mer/EAS_7mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
JPT_EAS_7mer_counts <- read_delim("subpops/7mer/JPT_EAS_7mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
CDX_EAS_7mer_counts <- read_delim("subpops/7mer/CDX_EAS_7mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
```

```{r F2AB setup methods}
# given: count1 and count2: pop-specific polymorphism dataframes; Mut: 3mer subcontext of interest,
# generates a scatter plot of rate for mut in population 1 by population 2
subrate.scplot <- function(count1, count2, mut, pops = c("Pop 1", "Pop 2"), label = c(), lm = F, lims = c(0,0), widemargin = F){
  pop1.mut <- subset(count1, count1$X3mer == mut)
  pop2.mut <- subset(count2, count2$X3mer == mut)
  sample.size <- pop1.mut$Count + pop2.mut$Count
  n <- nchar(mut)
  ref <- substr(mut, 1, n-3)
  alt <- substr(mut, n, n)
  
  #make plot
  p_plot <- qplot(pop1.mut$Rate, pop2.mut$Rate) +
    labs(x = bquote(.(ref)%->%.(alt) ~ .(paste("mutation rate in", pops[1]))), y = bquote(.(ref)%->%.(alt) ~ .(paste("mutation rate in", pops[2])))) +
    theme(legend.title = element_blank(), 
          legend.justification= c(1,0), 
          legend.position=c(1,0),
          legend.text = element_text(size = rel(0.75)),
          legend.key.size = unit(.4, "cm"),
          axis.text=element_text(size=8),
          text = element_text(size = 9))+
    geom_point(aes(colour = log(base = 10, x = sample.size)), size = 1.25) + 
    scale_colour_gradient(low = "orange", high = "blue")+
    geom_abline(aes(intercept=0,slope=1), size = .5)# + 
    #coord_fixed(ratio = 1, 
    #            xlim = c(0, max(pop1.mut$Rate, pop2.mut$Rate)),
    #            ylim = c(0, max(pop1.mut$Rate, pop2.mut$Rate)))
  
  if (lm){
    mod1 <- lm(pop2.mut$Rate ~ pop1.mut$Rate)
    pred <- predict(mod1, interval = "prediction")
    
    p_plot <- p_plot + stat_smooth(method = lm, se = FALSE, fullrange = T)+
      geom_line(aes(y = pred[,2]), color = "red", linetype = "dashed", size = 1)+
      geom_line(aes(y = pred[,3]), color = "red", linetype = "dashed", size = 1)
  }
  
  if (length(label!=0)){
    #set aside contexts to label
    dat <- data.frame(cbind(pop1.mut$Context, pop1.mut$Rate, pop2.mut$Rate), stringsAsFactors = F)
    lab <- subset(dat,  is.element(dat[,1], label))
    
    if (length(lab[,1]!=0)){
      lab[,c(2,3)] <- sapply(lab[,c(2,3)], as.numeric)
      p_plot <- p_plot + geom_label_repel(data = lab, aes(lab[,2], lab[,3],
                                   label = lab[,1]), size = 2.5, box.padding = unit(1, "lines"),
                                   point.padding = unit(.3, "lines"),
                                   nudge_x = 1.5e-9, nudge_y = 1.5e-9, color = "purple4")
    }
  }
  
  if (sum(lims) != 0){
    p_plot <- p_plot + 
    coord_fixed(ratio = 1, 
                xlim = lims,
                ylim = lims)
  } else {
    p_plot <- p_plot +
          coord_fixed(ratio = 1, 
                xlim = c(0, max(pop1.mut$Rate, pop2.mut$Rate)),
                ylim = c(0, max(pop1.mut$Rate, pop2.mut$Rate)))
  }

  if (widemargin){
    p_plot <- p_plot + theme(plot.margin = unit(c(2, 1, 4, 1), "lines"))
  }
  return(p_plot)
}
```

```{r F2AB make, fig.height=3.25, fig.width=7.5}
a <- subrate.scplot(CDX_EAS_7mer_counts, JPT_EAS_7mer_counts, "ACG->T", pops = c("Chinese Dai", "Japanese"))
b <- subrate.scplot(EAS_7mer_counts, EUR_7mer_counts, "TCC->T", pops = c("East Asia", "Europe"), lims = c(0,1.945e-8))
grid.arrange(a, b, ncol = 2)
```

# Figure 3

## A: table of X enriched polymorphisms

We can obtain the first set of fdr-adjusted p values using a pairwise chi squared test between CDX and JPT 7mers whose 3mer subcontext is a part of signal 4.

```{r F3A data}
gw_7mer_counts <- read_delim("gw_counts/gw_7mer_counts.txt", 
                             "\t", escape_double = FALSE, trim_ws = TRUE)
```

```{r JPTCDX 7mers test, echo = F}
p.CDXJPT <- pairwise.chi(CDX_EAS_7mer_counts, JPT_EAS_7mer_counts)
p.CDXJPT <- subset(p.CDXJPT, is.element(CDX_EAS_7mer_counts$X3mer, c("AAC->C", "CAC->C", "TAT->T", "GAC->C", "TAC->C")))
p.CDXJPT$fdr <- p.adjust(p.CDXJPT$p, method = "fdr")
p.CDXJPT <- p.CDXJPT[order(p.CDXJPT$fdr),]
kable(subset(p.CDXJPT, p.CDXJPT$fdr < 0.05), row.names = F, digits = 500)

#to find the fold enrichemnt, perform the following calculation:
k <- which(JPT_EAS_7mer_counts$Context == "CAAACCC->C");JPT_EAS_7mer_counts$Rate[k]/CDX_EAS_7mer_counts$Rate[k]
```
Next, we have to run a test for X enrichment, described in the paper.
```{r def preprocessor, echo = F}
X.preprocessing <- function(counts, gw, muts = c()){
  
  # if muts not specified, assume whole dataframe is used
  if (length(muts) == 0){
    muts <- counts$Context
  }
  counts <- subset(counts, is.element(counts$Context, muts))
  autosomes <-counts$Count-counts$chrX
  
  # construct data frame
  result <- data.frame(matrix(ncol=3,nrow=length(counts$Context)))
  colnames(result) <- c("Context", "Autosomes", "X")
  result$Context <- counts$Context
  result$Autosomes <- autosomes
  result$X <- counts$chrX
  
  # add gw_sites to data
  result$Autosomal_sites <- rep(0, length(result$Context))
  result$X_sites <- rep(0, length(result$Context))
  
  for (i in 1:length(result$Context)){
    mut <- as.character(result$Context[i])
    context <- substr(mut, 1, nchar(mut)-3)
    j <- which(gw$Context == context)
    result$Autosomal_sites[i] <- gw$GW_total[j]- gw$X[j]
    result$X_sites[i] <- gw$X[j]
  }

  return(result)
}
```


```{r, setup for X test, echo = F}
JPT7mers <- subset(p.CDXJPT$Context, p.CDXJPT$fdr < 0.05)
data <- X.preprocessing(EAS_7mer_counts, gw_7mer_counts, c())
```

```{r x test, echo = F}
data$alpha <- rep(1, length(data$Context))
data$p.0 <- rep(0, length(data$Context))
data$p.MLE <- rep(0, length(data$Context))
data$p <- rep(1, length(data$Context))

muts.X <- sum(data$X)
sites.X <- sum(data$X_sites)
muts.A <- sum(data$Autosomes)
sites.A <- sum(data$Autosomal_sites)

data <- subset(data, is.element(data$Context, JPT7mers))

#remove the data from these sites from background before estimating correction
muts.X <- muts.X - sum(data$X)
sites.X <- sites.X - sum(data$X_sites)
muts.A <- muts.A - sum(data$Autosomes)
sites.A <- sites.A - sum(data$Autosomes)

alpha <- (muts.X/sites.X)/(muts.A/sites.A)

for (i in 1:length(data$Context)){
  # estimate parameters and run test
  data$alpha[i] <- alpha
  p.0 <- alpha*(data$Autosomes[i]/data$Autosomal_sites[i])
  data$p.0[i] <- p.0
  data$p.MLE[i] <- data$X[i]/data$X_sites[i]
  
  data$p[i] <- binom.test(data$X[i], n = data$X_sites[i], p = p.0, alternative = "greater")$p.value
  
  if (data$Autosomes[i]< 15){
    data$p[i] <- 1
  }
  
}

data$Expected <- data$p.0*data$X_sites

kable(data, digits = 50, row.names = F)
```

##BC

These two panels use datasets and functions:

* **subrate.scplot**
* **CI.plot.subpop.bygroup**
* *7mer count dataframes for all EAS subpops*

```{r F3BC }
KHV_EAS_7mer_counts <- read_delim("subpops/7mer/KHV_EAS_7mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
CHS_EAS_7mer_counts <- read_delim("subpops/7mer/CHS_EAS_7mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
CHB_EAS_7mer_counts <- read_delim("subpops/7mer/CHB_EAS_7mer_counts.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
```

```{r F3BC setup data}
EASsubpops <- list(CDX_EAS_7mer_counts, KHV_EAS_7mer_counts, CHS_EAS_7mer_counts, CHB_EAS_7mer_counts, JPT_EAS_7mer_counts)
EASpopnames <- c("CDX", "KHV", "CHS", "CHB", "JPT")
```

```{r F3BC make, fig.height = 4, fig.width = 7}
b <- subrate.scplot(CDX_EAS_7mer_counts, JPT_EAS_7mer_counts, "AAC->C", c("Chinese Dai", "Japanese"), JPT7mers, lims = c(0,1.24e-8), widemargin = T)
c <- CI.plot.subpop.bygroup(EASsubpops, JPT7mers, EASpopnames, rep("red", 5), "significant 7-mers within profile #4")
grid.draw(cbind(ggplotGrob(b), ggplotGrob(c), size = "last"))
```

# Figure 4

##A

```{r F4 upload data}
SAS_7mer_counts <- read_delim("7mer/SAS_7mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
AFR_7mer_counts <- read_delim("7mer/AFR_7mer_counts.txt", 
                              "\t", escape_double = FALSE, trim_ws = TRUE)
```

```{r F4A make}
# calculate ordered p values
p.7mer <- fourway.chi(AFR_7mer_counts, EUR_7mer_counts, EAS_7mer_counts, SAS_7mer_counts)
o.p.7mer <- ordered.p(p.7mer)

# extract significantly variable mutation types and order by p value
alpha <- 0.05/length(o.p.7mer$Context)
o.sig.7mer <- subset(o.p.7mer, o.p.7mer$p < alpha)
o.sig.7mer <- o.sig.7mer[order(o.sig.7mer$p),]

# filter types from known 3mer signals
EUR.signal <- c("TCC->T", "ACC->T", "TCT->T", "CCC->T")
new.signal <- c("GAT->T", "ACC->A", "GAC->T", "ACG->T", "CCG->T", "GCG->T", "TCG->T")
o.new.7mers <- subset(o.sig.7mer, !is.element(o.sig.7mer$X3mer, c(EUR.signal, new.signal)))

rates <- data.frame(cbind(AFR_7mer_counts$Rate, EUR_7mer_counts$Rate, SAS_7mer_counts$Rate, EAS_7mer_counts$Rate)/AFR_7mer_counts$Rate)
rates$Context <- AFR_7mer_counts$Context
rates <- subset(rates, is.element(rates$Context, o.new.7mers$Context))
table4A <- merge(rates, o.new.7mers, by = "Context")

table4A <- table4A[order(table4A$p),][,c(1:5, 13)]
colnames(table4A)<- c("Context", "AFR relative rate", "EUR relative rate", "SAS relative rate", "EAS relative rate", "p")
table4A <- head(table4A, 5)

# plot significant 7mers and print most signif. new results
kable(table4A, digits = 600, row.names = F,
      caption = "5 most significant new 7mers using ordered p value correction")
```

The code below checks for significant pairwise differences with AFR using p-ordered correction.  This determines which reates are boldface in Figure4A:

```{r}
# Europe
pAFRvEUR <- pairwise.chi(AFR_7mer_counts, EUR_7mer_counts)
opAFRvEUR <- pairwise.op(pAFRvEUR)
opAFRvEUR <- subset(opAFRvEUR, opAFRvEUR$p < 1e-7)
kable(subset(opAFRvEUR, is.element(opAFRvEUR$Context, c("CAAACCC->C", "TTTATTT->T", "TTTAAAA->T", "ATTAAAA->T", "AAACAAA->A"))))

# South Asia
pAFRvSAS <- pairwise.chi(AFR_7mer_counts, SAS_7mer_counts)
opAFRvSAS <- pairwise.op(pAFRvSAS)
opAFRvSAS <- subset(opAFRvSAS, opAFRvSAS$p < 1e-7)
kable(subset(opAFRvSAS, is.element(opAFRvSAS$Context, c("CAAACCC->C", "TTTATTT->T", "TTTAAAA->T", "ATTAAAA->T", "AAACAAA->A"))))

# East Asia
pAFRvEAS <- pairwise.chi(AFR_7mer_counts, EAS_7mer_counts)
opAFRvEAS <- pairwise.op(pAFRvEAS)
opAFRvEAS <- subset(opAFRvEAS, opAFRvEAS$p < 1e-7)
kable(subset(opAFRvEAS, is.element(opAFRvEAS$Context, c("CAAACCC->C", "TTTATTT->T", "TTTAAAA->T", "ATTAAAA->T", "AAACAAA->A"))))
```


##BC

We can't use my usual graphing function to make Figure 4B because there are '$\rightarrow$' characters that we need to insert in the plot text.  We will also need the following:

* **subrate.scplot**
* *7mer count dataframes for all nonadmixed continental populations*

```{r F4B set up data}
muts <- c("TTTAAAA->T", "ATTAAAA->T")
AFR <- AFR_7mer_counts
EUR <- EUR_7mer_counts
EAS <- EAS_7mer_counts
SAS <- SAS_7mer_counts
```

```{r F4B make}
#NOTE: muts must all be from different contexts.  Otherwise this will do weird things.
muts.i <- which(is.element(AFR$Context, muts))
popnames <- c("Africa","Europe", "South\nAsia", "East\nAsia")
colors <- c("forestgreen", "darkblue", "magenta","red")

#have to do a silly workaround or R will sort popnames alphanumerically
poplabs <- factor(popnames, levels= popnames)

#cycle through pops and get counts for mut
counts <- rep(0, 4)
sums <- rep(0, 4)
pops <- list(AFR, EUR, SAS, EAS)

for (i in 1:length(pops)){
  counts[i] <- sum(pops[[i]]$Count[muts.i]) #number of obersvations of muts in pop
  sums[i]<- sum(pops[[i]]$Count)#total polymorphisms in pop
}

#estimate substitution probability
N.c <- sum(AFR$context_in_genome[muts.i])
theta <- counts/N.c
L <- theta - 1.96*sqrt(theta*(1-theta)/N.c)
U <- theta + 1.96*sqrt(theta*(1-theta)/N.c)

#normalize to rate estimate; assume genome wide subsitution probability is measured without error
norm <- 1.2E-8*(sum(as.numeric(AFR$context_in_genome))/3)/sums

df <- data.frame(cbind(popnames, theta*norm, L*norm, U*norm))
plotcol <- reorder(colors, theta*norm)

b <- ggplot(df, aes(reorder(popnames, c(1,2,3,4)), theta*norm)) +
  geom_point(size = 3, color = plotcol) +
  geom_errorbar(aes(ymax = U*norm, ymin = L*norm), color = plotcol, size =.75)+
  labs(y =  bquote(paste("Mutation rate of")~.("TTTAAAA")%->%.("T")~paste("and")~.("ATTAAAA")%->%.("T"))) + #y axis label
  theme(axis.text.x = element_text(size = rel(.9)), axis.title.x = element_blank(), #adjust text sizes
        axis.title.y = element_text(size = rel(1)), axis.text.y = element_text(size = rel(1), angle = 0, hjust = 0.5), title = element_text(size = rel(.7)),
        legend.position = 'none')
```

```{r F4BC make, fig.width=7, fig.height = 3.25}
c <- subrate.scplot(EUR_7mer_counts, AFR_7mer_counts, "TAA->T", c("Europe", "Africa"), c("ATTAAAA->T", "TTTAAAA->T"), lims = c(0, 2.05e-8))
grid.arrange(b, c, ncol = 2)
grid.draw(cbind(ggplotGrob(b), ggplotGrob(c), size = "last"))
```

